{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import subprocess\n",
    "\n",
    "def run_forecasting_single_or_all(\n",
    "    single_file_path=r'E:\\chaosgrandfinale\\fnn-master\\blk1.txt',\n",
    "    single_psr_delay=9,\n",
    "    single_psr_dim=6\n",
    "):\n",
    "    \"\"\"\n",
    "    If single_file_path is None, process all .txt files in chaotic_folder recursively.\n",
    "    If single_file_path is not None, process only that .txt file using the given PSR values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Paths\n",
    "    chaotic_folder = r\"E:\\forecasting1\\forecastingfolder1\\chaotic_columns\"\n",
    "    lyapunov_folder = r\"E:\\forecasting1\\forecastingfolder1\\lyapunov_result\"\n",
    "\n",
    "    # Base arguments for run.py\n",
    "    base_command = [\n",
    "        \"python\", \"run.py\",\n",
    "        \"--model_id\", \"blk_test_96_96\",\n",
    "        \"--model\", \"Attraos\",\n",
    "        \"--data\", \"custom\",\n",
    "        \"--features\", \"S\",\n",
    "        \"--enc_in\", \"1\",\n",
    "        \"--dec_in\", \"1\",\n",
    "        \"--c_out\", \"1\",\n",
    "        \"--seq_len\", \"96\",\n",
    "        \"--label_len\", \"24\",\n",
    "        \"--pred_len\", \"48\",\n",
    "        \"--batch_size\", \"32\",\n",
    "        \"--e_layers\", \"1\",\n",
    "        \"--learning_rate\", \"0.0001\",\n",
    "        \"--is_training\", \"1\",\n",
    "        \"--root_path\", chaotic_folder,  # common base folder\n",
    "        \"--gpu\", \"0\",\n",
    "        \"--FFT_evolve\", \"True\",\n",
    "        \"--multi_res\", \"True\"\n",
    "    ]\n",
    "\n",
    "    # Minimum required number of data points\n",
    "    min_data_length = 206  # e.g., 110 + 96\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Case 1: A single file is specified.\n",
    "    # ---------------------------------------------------------------------\n",
    "    if single_file_path is not None:\n",
    "        if not os.path.isfile(single_file_path):\n",
    "            print(f\"Error: single_file_path does not exist: {single_file_path}\")\n",
    "            return\n",
    "\n",
    "        # Make sure we have either both or neither. If user explicitly\n",
    "        # sets single_psr_delay / single_psr_dim, use them; otherwise skip.\n",
    "        # We'll assume that if user calls single_file_path, they also\n",
    "        # set single_psr_delay/dim, but you can tweak logic if needed.\n",
    "        if single_psr_delay is None or single_psr_dim is None:\n",
    "            print(\"You specified a single_file_path but did not provide PSR_delay or PSR_dim. \"\n",
    "                  \"Either provide them or set single_file_path=None for the all-files flow.\")\n",
    "            return\n",
    "\n",
    "        # Check length\n",
    "        try:\n",
    "            with open(single_file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            if len(lines) < min_data_length:\n",
    "                print(f\"File {single_file_path} is too short (length {len(lines)}); \"\n",
    "                      f\"required >= {min_data_length}. Skipping.\")\n",
    "                return\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {single_file_path}: {e}\")\n",
    "            return\n",
    "\n",
    "        # Derive the team_name from the immediate parent folder\n",
    "        team_name = os.path.basename(os.path.dirname(single_file_path))\n",
    "\n",
    "        # data_path relative to chaotic_folder\n",
    "        relative_data_path = os.path.relpath(single_file_path, chaotic_folder)\n",
    "\n",
    "        # Build command\n",
    "        cmd = base_command + [\n",
    "            \"--data_path\", relative_data_path,\n",
    "            \"--PSR_delay\", str(single_psr_delay),\n",
    "            \"--PSR_dim\", str(single_psr_dim),\n",
    "        ]\n",
    "\n",
    "        print(\"\\nRunning command (single file):\\n\", \" \".join(cmd), \"\\n\")\n",
    "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Stream stdout line by line\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output:\n",
    "                print(output, end='')\n",
    "            elif process.poll() is not None:\n",
    "                break\n",
    "\n",
    "        # Read and print any remaining stderr\n",
    "        stderr = process.stderr.read()\n",
    "        if stderr:\n",
    "            print(\"===== STDERR =====\")\n",
    "            print(stderr)\n",
    "\n",
    "        return_code = process.wait()\n",
    "        print(f\"[Process exited with code {return_code}]\\n\")\n",
    "        return\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Case 2: single_file_path is None -> process ALL .txt files as before.\n",
    "    # ---------------------------------------------------------------------\n",
    "    all_txt_files = glob.glob(os.path.join(chaotic_folder, \"**\", \"*.txt\"), recursive=True)\n",
    "    print(f\"Found {len(all_txt_files)} .txt files under {chaotic_folder} (recursive).\")\n",
    "\n",
    "    for txt_path in all_txt_files:\n",
    "        # Parse the folder name (team name) from the immediate parent directory\n",
    "        team_name = os.path.basename(os.path.dirname(txt_path))\n",
    "\n",
    "        # Path to the corresponding CSV\n",
    "        denoised_csv = os.path.join(lyapunov_folder, f\"{team_name}.csv\")\n",
    "        if not os.path.isfile(denoised_csv):\n",
    "            print(f\"CSV not found for team {team_name}: {denoised_csv}\")\n",
    "            continue\n",
    "\n",
    "        # Get the .txt file base name\n",
    "        txt_filename = os.path.splitext(os.path.basename(txt_path))[0]\n",
    "\n",
    "        psr_delay = None\n",
    "        psr_dim = None\n",
    "\n",
    "        # Open the CSV and find the row\n",
    "        with open(denoised_csv, mode=\"r\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "            for row in reader:\n",
    "                # Case-insensitive match\n",
    "                if row[\"Column_Name\"].strip().lower() == txt_filename.lower():\n",
    "                    psr_delay = row[\"Optimal_Time_Delay\"]\n",
    "                    psr_dim = row[\"Optimal_Embedding_Dimension\"]\n",
    "                    break\n",
    "\n",
    "        if not psr_delay or not psr_dim:\n",
    "            print(f\"No matching row found in {denoised_csv} for {txt_filename}\")\n",
    "            continue\n",
    "\n",
    "        # Check length\n",
    "        try:\n",
    "            with open(txt_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            if len(lines) < min_data_length:\n",
    "                print(f\"File {txt_path} is too short (length {len(lines)}); required >= {min_data_length}. Skipping.\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {txt_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Compute the relative data_path\n",
    "        relative_data_path = os.path.relpath(txt_path, chaotic_folder)\n",
    "\n",
    "        # Construct command\n",
    "        cmd = base_command + [\n",
    "            \"--data_path\", relative_data_path,\n",
    "            \"--PSR_delay\", str(psr_delay),\n",
    "            \"--PSR_dim\", str(psr_dim),\n",
    "        ]\n",
    "\n",
    "        print(\"\\nRunning command:\\n\", \" \".join(cmd), \"\\n\")\n",
    "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Stream stdout line by line\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output:\n",
    "                print(output, end='')\n",
    "            elif process.poll() is not None:\n",
    "                break\n",
    "\n",
    "        # Read and print any remaining stderr\n",
    "        stderr = process.stderr.read()\n",
    "        if stderr:\n",
    "            print(\"===== STDERR =====\")\n",
    "            print(stderr)\n",
    "\n",
    "        return_code = process.wait()\n",
    "        print(f\"[Process exited with code {return_code}]\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running command (single file):\n",
      " python run.py --model_id blk_test_96_96 --model Attraos --data custom --features S --enc_in 1 --dec_in 1 --c_out 1 --seq_len 96 --label_len 24 --pred_len 48 --batch_size 32 --e_layers 1 --learning_rate 0.0001 --is_training 1 --root_path E:\\forecasting1\\forecastingfolder1\\chaotic_columns --gpu 0 --FFT_evolve True --multi_res True --data_path ..\\..\\..\\chaosgrandfinale\\fnn-master\\blk1.txt --PSR_delay 9 --PSR_dim 6 \n",
      "\n",
      "True\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           blk_test_96_96      Model:              Attraos             \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          E:\\forecasting1\\forecastingfolder1\\chaotic_columns\n",
      "  Data Path:          ..\\..\\..\\chaosgrandfinale\\fnn-master\\blk1.txtFeatures:           S                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          24                  \n",
      "  Pred Len:           48                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             1                   Dec In:             1                   \n",
      "  C Out:              1                   d model:            512                 \n",
      "  n heads:            8                   e layers:           1                   \n",
      "  d layers:           1                   d FF:               2048                \n",
      "  Moving Avg:         25                  Factor:             1                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "  Output Attention:   0                   \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       50                  Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                test                Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_blk_test_96_96_Attraos_custom_ftS_sl96_ll24_pl48_dm512_nh8_el1_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 267\n",
      "val 91\n",
      "test 89\n",
      "Parameters: 0.072112\n",
      "Epoch: 1 cost time: 73.13464450836182\n",
      "Epoch: 1, Steps: 8 | Train Loss: 1.7567722 | Train MSE: 1.5529913, Train RMSE: 1.2461907 || Vali MSE: 1.6374168, Vali RMSE: 1.2796159 || Test MSE: 1.4121928, Test RMSE: 1.1883572\n",
      "Validation loss decreased (inf --> 1.637417).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 2 cost time: 68.75187158584595\n",
      "Epoch: 2, Steps: 8 | Train Loss: 1.4078620 | Train MSE: 1.2439113, Train RMSE: 1.1153077 || Vali MSE: 1.3060248, Vali RMSE: 1.1428144 || Test MSE: 1.1149013, Test RMSE: 1.0558889\n",
      "Validation loss decreased (1.637417 --> 1.306025).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 3 cost time: 74.98062801361084\n",
      "Epoch: 3, Steps: 8 | Train Loss: 1.1533770 | Train MSE: 1.0436291, Train RMSE: 1.0215816 || Vali MSE: 1.0776496, Vali RMSE: 1.0380991 || Test MSE: 0.9052321, Test RMSE: 0.9514368\n",
      "Validation loss decreased (1.306025 --> 1.077650).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 4 cost time: 71.40323662757874\n",
      "Epoch: 4, Steps: 8 | Train Loss: 0.9707803 | Train MSE: 0.8989300, Train RMSE: 0.9481192 || Vali MSE: 0.8578640, Vali RMSE: 0.9262094 || Test MSE: 0.7607468, Test RMSE: 0.8722080\n",
      "Validation loss decreased (1.077650 --> 0.857864).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 5 cost time: 72.59462356567383\n",
      "Epoch: 5, Steps: 8 | Train Loss: 0.8497054 | Train MSE: 0.7979743, Train RMSE: 0.8932941 || Vali MSE: 0.7456324, Vali RMSE: 0.8635001 || Test MSE: 0.6622820, Test RMSE: 0.8138071\n",
      "Validation loss decreased (0.857864 --> 0.745632).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 6 cost time: 56.74733829498291\n",
      "Epoch: 6, Steps: 8 | Train Loss: 0.7596304 | Train MSE: 0.7251194, Train RMSE: 0.8515394 || Vali MSE: 0.6430033, Vali RMSE: 0.8018749 || Test MSE: 0.5919477, Test RMSE: 0.7693814\n",
      "Validation loss decreased (0.745632 --> 0.643003).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 7 cost time: 55.5256929397583\n",
      "Epoch: 7, Steps: 8 | Train Loss: 0.6999483 | Train MSE: 0.6621449, Train RMSE: 0.8137228 || Vali MSE: 0.6368575, Vali RMSE: 0.7980335 || Test MSE: 0.5393420, Test RMSE: 0.7343991\n",
      "Validation loss decreased (0.643003 --> 0.636858).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 8 cost time: 61.73646140098572\n",
      "Epoch: 8, Steps: 8 | Train Loss: 0.6460552 | Train MSE: 0.6253945, Train RMSE: 0.7908189 || Vali MSE: 0.5534925, Vali RMSE: 0.7439708 || Test MSE: 0.4972779, Test RMSE: 0.7051794\n",
      "Validation loss decreased (0.636858 --> 0.553492).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 9 cost time: 54.5102379322052\n",
      "Epoch: 9, Steps: 8 | Train Loss: 0.6040467 | Train MSE: 0.5866018, Train RMSE: 0.7658994 || Vali MSE: 0.5255082, Vali RMSE: 0.7249194 || Test MSE: 0.4626569, Test RMSE: 0.6801888\n",
      "Validation loss decreased (0.553492 --> 0.525508).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 10 cost time: 65.60611772537231\n",
      "Epoch: 10, Steps: 8 | Train Loss: 0.5715363 | Train MSE: 0.5522210, Train RMSE: 0.7431157 || Vali MSE: 0.4644924, Vali RMSE: 0.6815367 || Test MSE: 0.4335513, Test RMSE: 0.6584461\n",
      "Validation loss decreased (0.525508 --> 0.464492).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 11 cost time: 55.23461866378784\n",
      "Epoch: 11, Steps: 8 | Train Loss: 0.5405597 | Train MSE: 0.5213290, Train RMSE: 0.7220312 || Vali MSE: 0.4602948, Vali RMSE: 0.6784503 || Test MSE: 0.4087199, Test RMSE: 0.6393120\n",
      "Validation loss decreased (0.464492 --> 0.460295).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 12 cost time: 55.233720779418945\n",
      "Epoch: 12, Steps: 8 | Train Loss: 0.5149893 | Train MSE: 0.4974812, Train RMSE: 0.7053235 || Vali MSE: 0.4406541, Vali RMSE: 0.6638178 || Test MSE: 0.3868603, Test RMSE: 0.6219810\n",
      "Validation loss decreased (0.460295 --> 0.440654).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 13 cost time: 54.37016439437866\n",
      "Epoch: 13, Steps: 8 | Train Loss: 0.4924037 | Train MSE: 0.4755024, Train RMSE: 0.6895668 || Vali MSE: 0.4008276, Vali RMSE: 0.6331095 || Test MSE: 0.3679658, Test RMSE: 0.6066018\n",
      "Validation loss decreased (0.440654 --> 0.400828).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 14 cost time: 56.68828463554382\n",
      "Epoch: 14, Steps: 8 | Train Loss: 0.4728355 | Train MSE: 0.4554858, Train RMSE: 0.6748969 || Vali MSE: 0.3929414, Vali RMSE: 0.6268504 || Test MSE: 0.3509747, Test RMSE: 0.5924312\n",
      "Validation loss decreased (0.400828 --> 0.392941).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 15 cost time: 56.00627899169922\n",
      "Epoch: 15, Steps: 8 | Train Loss: 0.4510386 | Train MSE: 0.4421457, Train RMSE: 0.6649404 || Vali MSE: 0.3650756, Vali RMSE: 0.6042149 || Test MSE: 0.3354316, Test RMSE: 0.5791646\n",
      "Validation loss decreased (0.392941 --> 0.365076).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 16 cost time: 53.83343172073364\n",
      "Epoch: 16, Steps: 8 | Train Loss: 0.4319386 | Train MSE: 0.4245280, Train RMSE: 0.6515581 || Vali MSE: 0.3580450, Vali RMSE: 0.5983686 || Test MSE: 0.3219248, Test RMSE: 0.5673842\n",
      "Validation loss decreased (0.365076 --> 0.358045).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 17 cost time: 53.407668352127075\n",
      "Epoch: 17, Steps: 8 | Train Loss: 0.4188314 | Train MSE: 0.4063579, Train RMSE: 0.6374620 || Vali MSE: 0.3441428, Vali RMSE: 0.5866368 || Test MSE: 0.3094009, Test RMSE: 0.5562382\n",
      "Validation loss decreased (0.358045 --> 0.344143).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 18 cost time: 53.249146461486816\n",
      "Epoch: 18, Steps: 8 | Train Loss: 0.3998050 | Train MSE: 0.3956767, Train RMSE: 0.6290284 || Vali MSE: 0.3328832, Vali RMSE: 0.5769603 || Test MSE: 0.2981404, Test RMSE: 0.5460224\n",
      "Validation loss decreased (0.344143 --> 0.332883).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 19 cost time: 53.201807737350464\n",
      "Epoch: 19, Steps: 8 | Train Loss: 0.3864741 | Train MSE: 0.3819158, Train RMSE: 0.6179934 || Vali MSE: 0.3339187, Vali RMSE: 0.5778570 || Test MSE: 0.2875944, Test RMSE: 0.5362783\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Parameters: 0.072112\n",
      "Epoch: 20 cost time: 53.280436992645264\n",
      "Epoch: 20, Steps: 8 | Train Loss: 0.3797530 | Train MSE: 0.3727205, Train RMSE: 0.6105084 || Vali MSE: 0.3110125, Vali RMSE: 0.5576850 || Test MSE: 0.2778928, Test RMSE: 0.5271553\n",
      "Validation loss decreased (0.332883 --> 0.311013).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 21 cost time: 53.66184639930725\n",
      "Epoch: 21, Steps: 8 | Train Loss: 0.3675500 | Train MSE: 0.3597165, Train RMSE: 0.5997637 || Vali MSE: 0.3113287, Vali RMSE: 0.5579684 || Test MSE: 0.2691398, Test RMSE: 0.5187868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Parameters: 0.072112\n",
      "Epoch: 22 cost time: 52.34638977050781\n",
      "Epoch: 22, Steps: 8 | Train Loss: 0.3595407 | Train MSE: 0.3493019, Train RMSE: 0.5910177 || Vali MSE: 0.2845788, Vali RMSE: 0.5334593 || Test MSE: 0.2604244, Test RMSE: 0.5103179\n",
      "Validation loss decreased (0.311013 --> 0.284579).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 23 cost time: 51.883358001708984\n",
      "Epoch: 23, Steps: 8 | Train Loss: 0.3463027 | Train MSE: 0.3425985, Train RMSE: 0.5853192 || Vali MSE: 0.2809783, Vali RMSE: 0.5300739 || Test MSE: 0.2526153, Test RMSE: 0.5026085\n",
      "Validation loss decreased (0.284579 --> 0.280978).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 24 cost time: 52.670820236206055\n",
      "Epoch: 24, Steps: 8 | Train Loss: 0.3391611 | Train MSE: 0.3310449, Train RMSE: 0.5753649 || Vali MSE: 0.2630575, Vali RMSE: 0.5128913 || Test MSE: 0.2452956, Test RMSE: 0.4952732\n",
      "Validation loss decreased (0.280978 --> 0.263058).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 25 cost time: 53.61505889892578\n",
      "Epoch: 25, Steps: 8 | Train Loss: 0.3280742 | Train MSE: 0.3229974, Train RMSE: 0.5683286 || Vali MSE: 0.2554856, Vali RMSE: 0.5054559 || Test MSE: 0.2385890, Test RMSE: 0.4884557\n",
      "Validation loss decreased (0.263058 --> 0.255486).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 26 cost time: 53.054259300231934\n",
      "Epoch: 26, Steps: 8 | Train Loss: 0.3210249 | Train MSE: 0.3135851, Train RMSE: 0.5599867 || Vali MSE: 0.2649278, Vali RMSE: 0.5147114 || Test MSE: 0.2319833, Test RMSE: 0.4816465\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Parameters: 0.072112\n",
      "Epoch: 27 cost time: 53.13325214385986\n",
      "Epoch: 27, Steps: 8 | Train Loss: 0.3106331 | Train MSE: 0.3085696, Train RMSE: 0.5554904 || Vali MSE: 0.2446043, Vali RMSE: 0.4945748 || Test MSE: 0.2261518, Test RMSE: 0.4755542\n",
      "Validation loss decreased (0.255486 --> 0.244604).  Saving model ...\n",
      "Parameters: 0.072112\n",
      "Epoch: 28 cost time: 53.2848002910614\n",
      "Epoch: 28, Steps: 8 | Train Loss: 0.3052056 | Train MSE: 0.3008569, Train RMSE: 0.5485042 || Vali MSE: 0.2523786, Vali RMSE: 0.5023729 || Test MSE: 0.2204355, Test RMSE: 0.4695056\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Parameters: 0.072112\n",
      "Epoch: 29 cost time: 53.81316590309143\n",
      "Epoch: 29, Steps: 8 | Train Loss: 0.2989169 | Train MSE: 0.2938911, Train RMSE: 0.5421172 || Vali MSE: 0.2469647, Vali RMSE: 0.4969554 || Test MSE: 0.2150867, Test RMSE: 0.4637744\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Parameters: 0.072112\n",
      "Epoch: 30 cost time: 53.177356481552124\n",
      "Epoch: 30, Steps: 8 | Train Loss: 0.2928324 | Train MSE: 0.2894204, Train RMSE: 0.5379781 || Vali MSE: 0.2450844, Vali RMSE: 0.4950600 || Test MSE: 0.2099537, Test RMSE: 0.4582070\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_blk_test_96_96_Attraos_custom_ftS_sl96_ll24_pl48_dm512_nh8_el1_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 89\n",
      "test shape: (89, 48, 1) (89, 48, 1)\n",
      "test shape: (89, 48, 1) (89, 48, 1)\n",
      "mse:0.22615182399749756, mae:0.35888907313346863, dtw:-999, rmse:0.4755542278289795,mape:3.147808074951172,mspe:495.85662841796875\n",
      "===== STDERR =====\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "22it [00:00, 202.00it/s]\n",
      "49it [00:00, 239.27it/s]\n",
      "74it [00:00, 242.04it/s]\n",
      "89it [00:01, 48.99it/s] \n",
      "\n",
      "[Process exited with code 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case A: Process the single .txt file you specified\n",
    "run_forecasting_single_or_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstoneproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
